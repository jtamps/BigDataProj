---
output:
  pdf_document: default
  html_document: default
---
# Pet-Match Recommender: Project Overview and Architecture

This document provides an overview of the Pet-Match Recommender project, detailing its components, data flow, and current progress. The goal is to build a prototype demonstrating how generative AI and advanced analytics can enhance shelter adoption rates by matching adopters with suitable pets.

## I. Data Foundation and Preprocessing

This section outlines the initial data generation, preparation, and the creation of a labeled training dataset.

1.  **Adopter Data Generation (`01_make_adopters.ipynb` equivalent):
    *   **Description:** A synthetic dataset of adopter personas forms a key input. As outlined in the initial project plan ("Create an adopter table and pseudo-labels"), this step was necessary due to the lack of readily available real-world adopter data for prototype development. The aim was to "invent a small but consistent adopter-profile table" using tools like Faker to sample attributes such as age, housing type, activity level, and prior pet ownership.
    *   **Implementation:** The initial generation of this data was performed using scripts and notebooks (e.g., `/Users/jeremy/Downloads/Adopter Dataset Creation.ipynb`), aligning with the project plan's directive to "Build 5–10 adopter personas... save 5,000–10,000 rows."
    *   **Key Output:** An "adopters_silver" dataset, stored in Google Cloud Storage (e.g., `gs://pairing-demo-bucket/Adopters/`).

2.  **Pet Data Sourcing & Preparation:
    *   **Description:** An existing dataset, `pets_silver`, containing information about adoptable pets, is utilized.
    *   **Implementation:** Initial loading and schema understanding were part of early data exploration (e.g., in `/Users/jeremy/Downloads/Dataset_Creation_and_Loading.ipynb`).
    *   **Key Output:** The `pets_silver` dataset, accessible in Google Cloud Storage (e.g., `gs://pairing-demo-bucket/pets_silver/`).

3.  **Training Pair Generation (`02_make_pairs.ipynb` equivalent):
    *   **Description:** To create a supervised learning dataset, adopter and pet data are cross-joined. A rule-based scoring function evaluates each potential (adopter, pet) pair. Pairs are then labeled as good (1) or bad (0) matches based on a predefined score threshold, resulting in a balanced training set.
    *   **Implementation:** This core logic is encapsulated in the `PairGCPLoad.py` script, which uses pandas to efficiently process the data and interact with Google Cloud Storage. The script represents an operationalized version of pairing logic prototyped in local notebooks (e.g., `/Users/jeremy/Downloads/Dataset_Creation_and_Loading.ipynb`).
    *   **Key Output:** The `train_pairs.parquet/` dataset, stored in GCS (e.g., `gs://pairing-demo-bucket/train_pairs.parquet/`). This dataset includes engineered features for both adopters and pets, along with the binary match label, and serves as the primary input for the recommendation model.
    *   **Noteworthy Milestones & Adaptations during this stage:**
        *   Successful configuration of the GCP environment for GCS bucket creation and permission management.
        *   Initial attempts with Dataproc Serverless were unsuccessful due to CPU quota issues.
        *   **Pivoted to pandas-based implementation:** This involved using pandas with the `gcsfs` package to interact with GCS for I/O, providing a simpler and more efficient solution for this specific task. The script `PairGCPLoad.py` was developed for this.
        *   Adaptation of the pairing script to handle data variability, such as the absence of a "Weight (lbs)" column in the `pets_silver` data. This involved removing weight-dependent features and adjusting the scoring logic to neutralize the impact of the missing size component.

## II. Recommendation Model (`03_train_wd_model.py`)

This component focuses on the machine learning model responsible for predicting pet-adopter compatibility.

1.  **Selected Model Architecture:**
    *   The project employs a **Wide-&-Deep** learning model. This architecture is well-suited for recommendation tasks with tabular data, as it combines the strengths of memorization (wide component) and generalization (deep component).
    *   **Tooling:** Implemented using TensorFlow Keras. The design aligns with principles of `tf.estimator.DNNLinearCombinedClassifier` or a similar custom Keras structure. The script `03_train_wd_model.py` handles the training.

2.  **Data Handling for Training:**
    *   The primary input for training is the `train_pairs.parquet/` dataset (located at `gs://pairing-demo-bucket/train_pairs.parquet/`), generated by `PairGCPLoad.py`.
    *   This dataset is downloaded locally to `/Users/jeremy/BigDataProj/model_training/data/train_pairs_local/` for training.
    *   It contains features and labels, loaded into a Pandas DataFrame, and then converted to `tf.data.Dataset` for efficient training.

3.  **Model Structure & Training Process:**
    *   **Wide Component:** Processes sparse, often one-hot encoded, features (e.g., pet breed, color, adopter housing) to learn feature interactions directly.
    *   **Deep Component:** A Deep Neural Network (DNN) that learns complex patterns from dense numerical features (e.g., pet age, adopter age) and also incorporates embeddings of categorical features.
    *   The model is trained using TensorFlow, with data typically fed through efficient input pipelines (e.g., `tf.data.Dataset`). Callbacks for early stopping and model checkpointing (saving the best model based on validation AUC) are used.

4.  **Evaluation and Output:**
    *   Model performance is assessed on a hold-out portion (20%) of the `train_pairs.parquet/` data.
    *   **Achieved Performance:**
        *   Test Loss: 0.0824
        *   Test Accuracy: 0.9686
        *   Test AUC: 0.9962
    *   The trained and validated model is serialized and saved as `pet_model.h5` locally in `/Users/jeremy/BigDataProj/model_training/` and then uploaded to `gs://pairing-demo-bucket/models/pet_model.h5`.

5.  **Challenges and Resolutions during Model Training:**
    *   **Input Shape Mismatches:** Initial training attempts faced `ValueError` exceptions due to incompatible input shapes between the `tf.data.Dataset` and the Keras model's `Input` layers.
        *   The Keras `Input` layers were defined with `shape=(1,)`, expecting 2D tensors like `(batch_size, 1)`.
        *   However, the `tf.data.Dataset` was yielding 1D tensors `(batch_size,)` for features.
    *   **Normalization Layer `adapt()` Issues:** The `tf.keras.layers.Normalization` layer's `adapt()` method was initially called with 1D data `(num_samples,)`, leading to an incorrect internal state (a very large number of non-trainable parameters was a symptom). It expects data of the same rank it will receive during training, i.e., `(num_samples, 1)` if processing single features.
    *   **Resolution:**
        *   The data for numerical features passed to `normalizer.adapt()` was reshaped from `(num_samples,)` to `(num_samples, 1)`.
        *   In the `prepare_dataset` function, both numerical and categorical feature arrays were reshaped from `(num_samples,)` to `(num_samples, 1)` before being converted into the `tf.data.Dataset`. This ensured consistency in data rank throughout the pipeline.

## III. Streamlit Demonstration Application (`app.py`)

An interactive web application built with Streamlit serves as the front-end to showcase the pet recommendation system.

1.  **Core Technologies:**
    *   Python, Streamlit, TensorFlow, Pandas, `openai` for LLM-generated explanations.

2.  **Key Loaded Resources for the Application:**
    *   **Trained Recommendation Model:** The `pet_model.h5` file.
    *   **OpenAI API Access:** The application connects to the OpenAI API (e.g., GPT-3.5 Turbo) for generating match explanations. Requires an API key managed via Streamlit secrets.
    *   **Pet Information:** The `pets_silver` dataset (or a suitable subset) providing details for recommended pets.
    *   **Adopter Data (for options):** The `adopters_silver.parquet` data is used to dynamically populate dropdown options for adopter characteristics (e.g., housing type, activity level), ensuring consistency with the training data's vocabulary.

3.  **Application Features and Workflow:**
    *   **Dynamic Adopter Profile Input:** Users define their profile directly within the app using interactive widgets in the sidebar (`st.sidebar`).
    *   **Recommendation Generation:** Upon clicking a "Find Matches" button, the application processes the adopter profile and pet data through the trained model to generate a ranked list of pet recommendations.
    *   **Display of Recommendations:** Recommended pets are displayed with details and their match score.
    *   **LLM-Generated Explanations:** For each match, a brief explanation is generated by the OpenAI API, highlighting why the pet might be a good fit.
    *   **Challenges and Iterations during App Development:**
        *   (Previous challenges related to local Llama and TensorFlow dtype mismatches remain relevant history but are now superseded by the OpenAI integration for explanations and subsequent refactors for batch processing and data handling.)
        *   **Streamlit `set_page_config()` Error:** Ensured `st.set_page_config()` was the very first Streamlit command executed.

### Recent Application Enhancements and Fixes (Late May 2024)

(This section describes enhancements made prior to the OpenAI migration)

*   **Llama-cpp-python Installation for macOS (Metal Support):** Resolved `ModuleNotFoundError` for `llama_cpp` on an Apple Silicon (M-series) Mac by reinstalling `llama-cpp-python` with specific compilation flags to enable Metal GPU acceleration.
*   **Keras Model Input Correction:** Addressed errors related to `Missing data for input` and discrepancies in expected feature names by the trained Keras model (`pet_model.h5`).
*   **Unique LLM Explanations (Local Llama):** Resolved an issue where the same local Llama-generated match explanation was displayed for all recommended pets by improving caching keys.

## VI. Recent Development and Changelog (Late May - Early June 2024)

This section details significant efforts in deploying the Streamlit application to Streamlit Community Cloud, along with substantial performance enhancements, UI/UX refinements, and bug fixes.

### A. Deployment to Streamlit Community Cloud

*   **Python Version Management:** Successfully configured Python 3.11.x for TensorFlow compatibility using `.python-version` and `runtime.txt`.
*   **Dependency Management for Cloud:** Iteratively refined `requirements.txt`. `llama-cpp-python` was initially problematic and later replaced by the `openai` library (see section C).
*   **Data and Model Path Handling:** Adjusted file paths for cloud deployment.
*   **Git Hygiene and Security:** Managed `.gitignore` for large files and sensitive data (`secrets.toml`).

### B. Performance Optimizations

*   **Batch Prediction Implementation:** Refactored pet-adopter matching to use batch predictions, significantly reducing prediction time. Addressed `fillna` errors for cloud compatibility.
*   **Cached Llama Import Check (Now Obsolete):** Initially cached local Llama import checks. This is no longer relevant after switching to OpenAI.

### C. Major LLM Refactor: Local Llama to OpenAI API (Early June 2024)

*   **Switched LLM Backend:** Replaced the local Llama model (`llama-cpp-python`) with the OpenAI API (e.g., GPT-3.5 Turbo) for generating match explanations.
    *   Removed all `llama-cpp-python` related code, dependencies, and local model file management.
    *   Added `openai` library to `requirements.txt`.
    *   Implemented OpenAI client initialization, fetching the API key from Streamlit secrets (`st.secrets["OPENAI_API_KEY"]`).
    *   Modified the `generate_match_explanation` function to use the OpenAI API.
    *   This change simplifies deployment by removing the need for a large local model file and local compute for LLM, at the cost of an external API dependency and associated key management.

### D. UI/UX Enhancements and Bug Fixes

*   **Refactored Application Structure (`app.py`):** Major refactor for improved error handling, efficiency, code organization (Config class, BatchProcessor, etc.).
*   **LLM Message Handling:** Removed UI messages related to local LLM unavailability.
*   **NaN Pet Name Handling:** Improved display of pets with missing/invalid names to show "Unnamed Pet" and cleaned unrenderable characters.

### E. General Code Health
*   Consistent use of logging, type hinting, and modular design.

## IV. Core Project Artifacts and Scripts

This section lists the key files, data, and scripts that constitute the project:

*   **Input Data for Model Training:** `train_pairs.parquet/`
*   **Adopter Data:** `gs://pairing-demo-bucket/Adopters/`
*   **Pet Data:** `gs://pairing-demo-bucket/pets_silver/`
*   **Data Processing Script (Pandas):** `PairGCPLoad.py`
*   **Model Training Script:** `03_train_wd_model.py`
*   **Trained Model File:** `pet_model.h5`
*   **Streamlit Application Script:** `app.py`

## V. Running and Deploying the Application

### A. Running Locally

1.  **Prerequisites:**
    *   Python 3.8+.

2.  **Setup:**
    *   Clone the repository.
    *   Navigate to the `streamlit_app` directory.
    *   Create and activate a Python virtual environment.
    *   Install required packages: `pip install -r requirements.txt`
    *   **OpenAI API Key Setup:**
        *   For local development, you can set the `OPENAI_API_KEY` as an environment variable:
          ```bash
          export OPENAI_API_KEY='your_openai_api_key_here'
          ```
        *   Alternatively, if running Streamlit locally and you have a `.streamlit/secrets.toml` file in your project root (or user .streamlit directory), you can add the key there:
          ```toml
          OPENAI_API_KEY = "your_openai_api_key_here"
          ```
          The application (`app.py`) is configured to read this secret via `st.secrets["OPENAI_API_KEY"]`.
    *   **Download Models and Data (Excluding LLM):**
        *   **Recommendation Model:** Ensure `pet_model.h5` is in the `streamlit_app/` directory.
        *   **Pet and Adopter Data:** Ensure `pets_silver_local` and `adopters_local` Parquet datasets are in `streamlit_app/data/` (or appropriate paths as configured in `app.py`).

3.  **Run the Application:**
    *   From the `streamlit_app` directory: `streamlit run app.py`

### B. Deployment Considerations (Streamlit Community Cloud)

*   **OpenAI API Key:** Ensure your `OPENAI_API_KEY` is added to your Streamlit Cloud app's secrets. In your app's settings on Streamlit Community Cloud, go to "Secrets" and add it in the `TOML` format:
    ```toml
    OPENAI_API_KEY = "your_openai_api_key_here"
    ```
*   **Dependencies:** The `openai` library will be installed from `requirements.txt`. No local LLM model file needs to be deployed with the app.
*   **Resource Limits:** Using the OpenAI API offloads the LLM computation, reducing local resource needs (CPU/RAM) compared to running a local Llama model.

This README provides a snapshot of the Pet-Match Recommender project's design, components, and the journey of its development, including the recent shift to using OpenAI for enhanced explanation generation. 